# -*- coding: utf-8 -*-
"""final_v1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jRg9JoFcF00lkbi8fZcYtfXs-Moi21NY

## Speaker Verification Workflow: Load Specs, Train & Evaluate

This notebook orchestrates the steps for preparing data, training speaker verification models (MobileNetV2, Fusion), and performing extensive evaluation.

**Workflow:**
1.  **Setup:** Mount Drive, define workspace.
2.  **Prepare Train Data:** Copy raw train WAVs, pre-processed train NPYs, AND existing high-quality train spectrograms from Drive to local runtime.
3.  **Train MobileNetV2:** Train from scratch using the copied local train spectrograms.
4.  **Prepare Test Data (Raw NPY):** Copy raw test WAVs locally, pre-process to NPY (local+Drive), generate NPY CSVs (local+Drive pointing).
5.  **Regenerate Test Spectrograms:** Generate high-quality PNG spectrograms locally for all test sets (clean, noisy, filtered).
6.  **Backup Test Spectrograms:** Copy locally generated test spectrograms to Drive for persistence.
7.  **Train Fusion Model:** Train from scratch using best SincNet/MobileNet checkpoints and local train data.
8.  **Evaluate Models:** Evaluate SincNet, MobileNetV2, and Fusion models on all three test sets (clean, noisy, filtered) using local data, calculating EER, AUC, FNMR@FMR, etc., and save results.

**Assumptions:**
* All necessary scripts exist in `$WORKSPACE/scripts/`.
* Model/Dataset definitions exist in `$WORKSPACE/models/` and `$WORKSPACE/datasets/`.
* Original raw pair CSVs exist on Drive.
* Original raw WAV data exists on Drive.
* Pre-processed train NPY files exist on Drive.
* **High-quality train spectrogram PNG files exist on Drive** (e.g., in `$WORKSPACE/data/spectrograms_generated_png/noisy_train/`).
* The corresponding **CSV pointing to these Drive spectrograms** exists (e.g., `$WORKSPACE/data/pairs/pairs_spec_train_drive.csv` - needed by `data_manager_v2.py` to find the files).
* `outputs/checkpoints/sincnet_best.pt` exists from prior SincNet training.
"""

# 1. Setup Environment
from google.colab import drive
import os
import json
from pathlib import Path
import time

print("Mounting Google Drive...")
drive.mount('/content/drive', force_remount=True)

WORKSPACE = Path("/content/drive/Shareddrives/VoiceAuth")

"""## 2. Generate Original Clean Raw Pair CSV

Creates the initial list of genuine/imposter pairs using the original clean VoxCeleb1 Dev WAV files.
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd $WORKSPACE
print("--- Generating Original Clean Raw Pairs CSV ---")

# Path to the original clean VoxCeleb1 Dev WAV directory on Drive
CLEAN_DEV_WAV_DIR = "/content/drive/Shareddrives/VoxCeleb1/Dev/wav"

# Output path for the raw pair CSV on Drive
RAW_CSV_CLEAN_TRAIN = WORKSPACE / "data/pairs/pairs_raw_clean_train.csv"

# Ensure parent directory exists
!mkdir -p "{RAW_CSV_CLEAN_TRAIN.parent}"

# Run the script (adjust --num_pairs or other args as needed)
# Example: Generate 1 million pairs total (adjust ratio as needed in script)
!python scripts/make_verification_pairs.py \
  "{CLEAN_DEV_WAV_DIR}" \
  "{RAW_CSV_CLEAN_TRAIN}" \
  --imposter_ratio 3 --seed 42

"""## Copy Clean WAVs Locally & Preprocess to NPY

Uses the `data_manager_v3.py` script to:
* Copy the clean WAV files listed in the CSV generated above from Drive to local storage.
* Preprocess these local WAVs into NPY format (saving both locally and back to Drive).
"""

print("--- Copying Clean WAVs Locally & Preprocessing to NPY (Local+Drive) ---")

!python scripts/data_manager_v3.py \
  --drive_workspace_dir="{WORKSPACE}" \
  --dataset_keys train_clean \
  --copy_raw \
  --preprocess_raw
  # --force_copy # Optional: Overwrite local WAVs
  # --force_preprocess # Optional: Overwrite NPYs

"""## 4. Generate Clean NPY Pair CSVs

Uses `data_manager_v3.py` to create the CSV files on Drive that point to the NPY files (both the local versions and the Drive versions).
"""

print("--- Generating Clean NPY Pair CSVs (Local & Drive Pointing) ---")

!python scripts/data_manager_v3.py \
  --drive_workspace_dir="{WORKSPACE}" \
  --dataset_keys train_clean \
  --gen_csv_local \
  --gen_csv_drive

"""## 5. Generate Clean Spectrograms Locally

Uses `make_spectrogram_pairs.py` with the *original clean raw pair CSV* and the *local clean WAV files* (copied in step 3) to generate high-quality PNG spectrograms locally. It also saves the CSV pointing to these *local* spectrograms onto Drive.
"""

print("--- Generating Clean Spectrograms Locally ---")

# Define local output directory for spectrogram images
LOCAL_SPEC_DIR_CLEAN_TRAIN = "/content/data/spectrograms/clean_train/"

# Define input raw pair CSV (original clean one on Drive)
RAW_CSV_CLEAN_TRAIN = WORKSPACE / "data/pairs/pairs_raw_clean_train.csv"

# Define output spectrogram pair CSV (containing LOCAL paths, saved to Drive)
SPEC_CSV_LOCAL_CLEAN_TRAIN = WORKSPACE / "data/pairs/pairs_spec_clean_train_local.csv"

# Ensure local output directory exists and is clean
!mkdir -p {LOCAL_SPEC_DIR_CLEAN_TRAIN}
!rm -rf {LOCAL_SPEC_DIR_CLEAN_TRAIN}/*

print("Generating Clean Train Spectrograms...")
!python scripts/make_spectrogram_pairs.py \
  "{RAW_CSV_CLEAN_TRAIN}" \
  "{LOCAL_SPEC_DIR_CLEAN_TRAIN}" \
  "{SPEC_CSV_LOCAL_CLEAN_TRAIN}" \
  --n_mels 80 \
  --n_fft 512 \
  --hop_length 160 \
  --img_size 224 \
  --img_format png \
  --duration 3.0

# 6. Backup Clean Spectrograms to Drive
print("--- Copying Generated Clean Train Spectrograms to Drive ---")

# Define the corresponding directory on DRIVE to save the images
DRIVE_SPEC_DIR_CLEAN_TRAIN = WORKSPACE / "data/spectrograms_generated_png/clean_train/" # New dir for clean PNGs

# Define the source (local) directory
LOCAL_SPEC_DIR_CLEAN_TRAIN = "/content/data/spectrograms/clean_train/"

# Ensure Drive directory exists
!mkdir -p "{DRIVE_SPEC_DIR_CLEAN_TRAIN}"

print(f"Copying from {LOCAL_SPEC_DIR_CLEAN_TRAIN} to {DRIVE_SPEC_DIR_CLEAN_TRAIN}...")
!cp -r -n {LOCAL_SPEC_DIR_CLEAN_TRAIN}* "{DRIVE_SPEC_DIR_CLEAN_TRAIN}/"
print("Copy complete.")

# 7. Generate Clean Spectrogram Drive CSV (Optional but Recommended)
print("--- Generating Clean Spectrogram Pair CSV (Drive Pointing) ---")

# Input: Original Raw Clean Pair CSV
RAW_CSV_CLEAN_TRAIN = WORKSPACE / "data/pairs/pairs_raw_clean_train.csv"
# Input: Base dir where ORIGINAL Clean WAVs reside on Drive
DRIVE_WAV_BASE_CLEAN = Path("/content/drive/Shareddrives/VoxCeleb1/Dev/wav")
# Input: Base dir where GENERATED Clean Specs reside on Drive
DRIVE_SPEC_BASE_CLEAN = WORKSPACE / "data/spectrograms_generated_png/clean_train/"
# Output: CSV pointing to DRIVE specs
OUTPUT_SPEC_CSV_DRIVE_CLEAN = WORKSPACE / "data/pairs/pairs_spec_clean_train_drive.csv"

# We need a function similar to generate_npy_csv but for specs
# For simplicity, let's reuse the logic inline here
import csv
from tqdm.notebook import tqdm

written_count = 0
skipped_count = 0
if not RAW_CSV_CLEAN_TRAIN.exists():
    print(f"ERROR: Original Raw CSV not found: {RAW_CSV_CLEAN_TRAIN}")
else:
    try:
        OUTPUT_SPEC_CSV_DRIVE_CLEAN.parent.mkdir(parents=True, exist_ok=True)
        with open(RAW_CSV_CLEAN_TRAIN, 'r', newline='') as infile, \
             open(OUTPUT_SPEC_CSV_DRIVE_CLEAN, 'w', newline='') as outfile:
            reader = csv.reader(infile)
            writer = csv.writer(outfile)
            header = next(reader)
            # Modify header if needed, e.g., ['file1_spec', 'file2_spec', 'label']
            writer.writerow(header)
            for row in tqdm(reader, desc="Gen Drive Spec CSV (Clean)"):
                if len(row) == 3:
                    wav_path1_str, wav_path2_str, label = row
                    try:
                        wav_path1 = Path(wav_path1_str)
                        wav_path2 = Path(wav_path2_str)
                        relative_path1 = wav_path1.relative_to(DRIVE_WAV_BASE_CLEAN)
                        relative_path2 = wav_path2.relative_to(DRIVE_WAV_BASE_CLEAN)
                        # Construct the spec path using the DRIVE spec base dir
                        spec_path1 = (DRIVE_SPEC_BASE_CLEAN / relative_path1).with_suffix(".png")
                        spec_path2 = (DRIVE_SPEC_BASE_CLEAN / relative_path2).with_suffix(".png")
                        writer.writerow([str(spec_path1), str(spec_path2), label])
                        written_count += 1
                    except ValueError as ve: skipped_count += 1
                    except Exception as e: skipped_count += 1; print(f"Error processing row {row}: {e}")
                else: skipped_count += 1
        print(f"Finished: Wrote {written_count} pairs to {OUTPUT_SPEC_CSV_DRIVE_CLEAN}. Skipped {skipped_count} pairs.")
    except Exception as e:
        print(f"ERROR during Drive Spec CSV generation: {e}")

print("--- Preparing Mixed Train Data Locally (Copying NPYs & Specs) ---")

# Use data_manager_v3 to copy both clean and noisy NPYs and Specs
!python scripts/data_manager_v3.py \
  --drive_workspace_dir="{WORKSPACE}" \
  --dataset_keys train_clean train_noisy \
  --load_npy \
  --copy_spec
  # --force_copy # Optional: Overwrite existing local files
  # --drive_npy_base_dir="..." # Optional: Specify if NPYs are not in default Drive location
  # --drive_spec_base # data_manager infers this from its internal config

print("--- Generating Local Train NPY CSVs (Clean & Noisy) ---")

# Generate NPY CSVs pointing to local files (saved to Drive)
!python scripts/data_manager_v3.py \
  --drive_workspace_dir="{WORKSPACE}" \
  --dataset_keys train_clean train_noisy \
  --gen_csv_local

# Verify local spec CSVs were created previously (in step 4 for clean, assumed pre-existing for noisy)
!ls -l "{WORKSPACE}/data/pairs/pairs_spec_clean_train_local.csv"
!ls -l "{WORKSPACE}/data/pairs/pairs_spec_train_local.csv"

# --- Combine Local CSVs ---
print("--- Combining Local CSVs for Mixed Training ---")
PAIRS_DIR = WORKSPACE / "data/pairs"

# Input LOCAL CSVs (Paths stored on Drive)
raw_clean_local_csv = PAIRS_DIR / "pairs_raw_clean_train_preprocessed_local.csv"
raw_noisy_local_csv = PAIRS_DIR / "pairs_raw_train_preprocessed_local.csv"
spec_clean_local_csv = PAIRS_DIR / "pairs_spec_clean_train_local.csv"
spec_noisy_local_csv = PAIRS_DIR / "pairs_spec_train_local.csv"

# Output MIXED LOCAL CSVs (Saved to Drive)
raw_mixed_local_csv = PAIRS_DIR / "pairs_raw_mixed_train_preprocessed_local.csv"
spec_mixed_local_csv = PAIRS_DIR / "pairs_spec_mixed_train_local.csv"

# --- Combine Raw CSVs ---
print(f"Combining Raw CSVs -> {raw_mixed_local_csv.name}")
try:
    df_raw_clean = pd.read_csv(raw_clean_local_csv)
    df_raw_noisy = pd.read_csv(raw_noisy_local_csv)
    df_raw_mixed = pd.concat([df_raw_clean, df_raw_noisy], ignore_index=True)
    df_raw_mixed = df_raw_mixed.sample(frac=1).reset_index(drop=True)
    df_raw_mixed.to_csv(raw_mixed_local_csv, index=False)
    print(f"Saved combined raw CSV with {len(df_raw_mixed)} pairs.")
except FileNotFoundError as e:
    print(f"Error: Input CSV not found: {e}. Cannot combine raw CSVs.")
except Exception as e:
    print(f"Error combining raw CSVs: {e}")

# --- Combine Spec CSVs ---
print(f"\nCombining Spectrogram CSVs -> {spec_mixed_local_csv.name}")
try:
    df_spec_clean = pd.read_csv(spec_clean_local_csv)
    df_spec_noisy = pd.read_csv(spec_noisy_local_csv)
    df_spec_mixed = pd.concat([df_spec_clean, df_spec_noisy], ignore_index=True)
    df_spec_mixed = df_spec_mixed.sample(frac=1).reset_index(drop=True)
    df_spec_mixed.to_csv(spec_mixed_local_csv, index=False)
    print(f"Saved combined spec CSV with {len(df_spec_mixed)} pairs.")
except FileNotFoundError as e:
    print(f"Error: Input CSV not found: {e}. Cannot combine spec CSVs.")
except Exception as e:
    print(f"Error combining spec CSVs: {e}")

# Define MIXED input CSVs (pointing to LOCAL data, stored on Drive)
RAW_MIXED_CSV = f"{WORKSPACE}/data/pairs/pairs_raw_mixed_train_preprocessed_local.csv"
SPEC_MIXED_CSV = f"{WORKSPACE}/data/pairs/pairs_spec_mixed_train_local.csv"

# Define paths to BEST embedder checkpoints from previous training
SINC_BEST_CKPT = "outputs/checkpoints/sincnet_best.pt"
MOBILENET_BEST_CKPT = "outputs/checkpoints/mobilenetv2_best.pt"

# Define a NEW output directory for fine-tuning results
FINETUNE_OUTPUT_DIR = "outputs_finetuned"

# Clean previous fine-tuning outputs (optional)
print(f"Cleaning previous fine-tuning outputs in {FINETUNE_OUTPUT_DIR}...")
!rm -rf "{FINETUNE_OUTPUT_DIR}/checkpoints/fusion_*.pt"
!rm -rf "{FINETUNE_OUTPUT_DIR}/metrics/fusion_*.json"

# --- Start Fine-tuning ---
print("--- Starting Fusion Model Fine-tuning on Mixed Data ---")
!python scripts/train_fusion.py \
  "{RAW_MIXED_CSV}" \
  "{SPEC_MIXED_CSV}" \
  --sincnet_ckpt "{SINC_BEST_CKPT}" \
  --mobilenet_ckpt "{MOBILENET_BEST_CKPT}" \
  --output_dir "{FINETUNE_OUTPUT_DIR}" \
  --device cuda \
  --epochs 20 \
  --batch_size 64 \
  --num_workers 8 \
  --lr 1e-5 \
  --patience 3 \
  --seed 42 \
  --no-freeze_embedders \
  # DO NOT USE --resume

# Cell 10 from previous notebook (Evaluation Code) remains the same,
# but ensure it loads the FINE-TUNED fusion checkpoint.

print("--- Evaluating Models --- ")
import torch
import numpy as np
from pathlib import Path
from sklearn.metrics import roc_curve, auc, roc_auc_score
from scipy.optimize import brentq
from scipy.interpolate import interp1d
import json
from tqdm.notebook import tqdm
import os
from collections import OrderedDict

# Assuming models and dataset classes are importable
try:
    from models.sincnet import SincNetEmbedding
    from models.mobilenet_embedding import MobileNetV2Embedding
    from scripts.train_fusion import FusionClassifier
    from scripts.train_sincnet import PairClassifier as SincPairClassifier
    from scripts.train_mobilenetv2 import PairClassifier as MobilePairClassifier
    from datasets.preprocessed_raw_dataset import RawAudioDatasetPreprocessed
    from datasets.spectrogram_dataset import MelSpectrogramPairDataset
except ImportError as e:
    print(f"ERROR: Could not import required modules: {e}")
    raise e # Stop execution if imports fail

# --- Configuration ---
WORKSPACE = Path(os.getcwd())
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
BATCH_SIZE = 128
NUM_WORKERS = 4
OUTPUT_DIR = Path("outputs") # Original output dir
FINETUNE_OUTPUT_DIR = Path("outputs_finetuned") # Finetuned output dir
RESULTS_FILE = FINETUNE_OUTPUT_DIR / "metrics" / "evaluation_results_finetuned.json" # Save results here

# --- Define Checkpoint Paths ---
sinc_best_ckpt_path = OUTPUT_DIR / "checkpoints" / "sincnet_best.pt"
mobilenet_best_ckpt_path = OUTPUT_DIR / "checkpoints" / "mobilenetv2_best.pt"
fusion_finetuned_best_ckpt_path = FINETUNE_OUTPUT_DIR / "checkpoints" / "fusion_best.pt" # Use fine-tuned fusion

# --- Define Test CSV Paths (Pointing to LOCAL data) ---
test_csv_paths = {
    "clean": {
        "raw": WORKSPACE / "data/pairs/pairs_raw_clean_test_preprocessed_local.csv",
        "spec": WORKSPACE / "data/pairs/pairs_spec_clean_test_local.csv"
    },
    "noisy": {
        "raw": WORKSPACE / "data/pairs/pairs_raw_noisy_test_preprocessed_local.csv",
        "spec": WORKSPACE / "data/pairs/pairs_spec_noisy_test_local.csv"
    },
    "filtered": {
        "raw": WORKSPACE / "data/pairs/pairs_raw_filtered_test_preprocessed_local.csv",
        "spec": WORKSPACE / "data/pairs/pairs_spec_filtered_test_local.csv"
    }
}

# --- Helper Functions (Copied from previous cell, ensure they are defined) ---
def load_state_dict_flexible(model_to_load, state_dict, strict=True):
    if not state_dict or not isinstance(state_dict, dict) or not state_dict.keys(): print("Warning: Received empty state_dict."); return
    first_key = list(state_dict.keys())[0]
    is_dp = first_key.startswith('module.')
    is_comp = first_key.startswith('_orig_mod.')
    new_state_dict = state_dict
    if is_comp: new_state_dict = OrderedDict((k.replace('_orig_mod.', '', 1), v) for k, v in new_state_dict.items()); first_key = list(new_state_dict.keys())[0]; is_dp = first_key.startswith('module.')
    if is_dp: new_state_dict = OrderedDict((k[7:], v) for k, v in new_state_dict.items())
    try: model_to_load.load_state_dict(new_state_dict, strict=strict)
    except RuntimeError as e:
         print(f"Warning: State dict loading error (strict={strict}): {e}. Attempting non-strict.")
         if strict:
              try: model_to_load.load_state_dict(new_state_dict, strict=False)
              except Exception as e2: print(f"ERROR: Non-strict load failed: {e2}")

def calculate_eer(y_true, y_score):
    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=1)
    eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr, fill_value="extrapolate")(x), 0., 1.)
    try: thresh = interp1d(fpr, thresholds, fill_value="extrapolate")(eer)
    except ValueError: thresh = thresholds[np.nanargmin(np.abs(fpr - (1 - tpr)))]
    return eer * 100, float(thresh)

def calculate_fmr_at_fnmr(y_true, y_score, target_fnmr):
    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=1); fnmr = 1 - tpr
    try:
        interp_fnmr_to_fpr = interp1d(fnmr, fpr, kind='linear', bounds_error=False, fill_value=(fpr[0], fpr[-1]))
        interp_fnmr_to_thresh = interp1d(fnmr, thresholds, kind='linear', bounds_error=False, fill_value=(thresholds[0], thresholds[-1]))
        fmr_at_target = interp_fnmr_to_fpr(target_fnmr); threshold_at_target = interp_fnmr_to_thresh(target_fnmr)
        interp_thresh_to_fnmr = interp1d(thresholds, fnmr, kind='linear', bounds_error=False, fill_value=(fnmr[0], fnmr[-1]))
        actual_fnmr = interp_thresh_to_fnmr(threshold_at_target)
        return float(fmr_at_target * 100), float(threshold_at_target), float(actual_fnmr * 100)
    except (ValueError, IndexError) as e: return float('nan'), float('nan'), float('nan')

# --- Load Models ---
print("\n--- Loading Models for Evaluation ---")
models_to_evaluate = {}

# Load Original SincNet + its PairClassifier
if sinc_best_ckpt_path.exists():
    try:
        sinc_model = SincNetEmbedding().to(DEVICE)
        sinc_clf = SincPairClassifier().to(DEVICE)
        sinc_ckpt = torch.load(sinc_best_ckpt_path, map_location=DEVICE)
        load_state_dict_flexible(sinc_model, sinc_ckpt['model'])
        if 'clf' in sinc_ckpt: load_state_dict_flexible(sinc_clf, sinc_ckpt['clf']); models_to_evaluate['sincnet_original'] = (sinc_model, sinc_clf); print(f"Loaded Original SincNet.")
        else: print(f"Warning: Classifier state ('clf') not found in {sinc_best_ckpt_path}.")
    except Exception as e: print(f"ERROR loading SincNet model/classifier: {e}")
else: print(f"SincNet checkpoint not found: {sinc_best_ckpt_path}")

# Load Original MobileNetV2 + its PairClassifier
if mobilenet_best_ckpt_path.exists():
    try:
        mobilenet_model = MobileNetV2Embedding(freeze=False).to(DEVICE)
        mobilenet_clf = MobilePairClassifier().to(DEVICE)
        mobilenet_ckpt = torch.load(mobilenet_best_ckpt_path, map_location=DEVICE)
        load_state_dict_flexible(mobilenet_model, mobilenet_ckpt['model'], strict=False)
        if 'clf' in mobilenet_ckpt: load_state_dict_flexible(mobilenet_clf, mobilenet_ckpt['clf']); models_to_evaluate['mobilenet_original'] = (mobilenet_model, mobilenet_clf); print(f"Loaded Original MobileNetV2.")
        else: print(f"Warning: Classifier state ('clf') not found in {mobilenet_best_ckpt_path}.")
    except Exception as e: print(f"ERROR loading MobileNetV2 model/classifier: {e}")
else: print(f"MobileNetV2 checkpoint not found: {mobilenet_best_ckpt_path}")

# Load Fine-tuned Fusion components
if fusion_finetuned_best_ckpt_path.exists():
    try:
        fusion_sinc_ft = SincNetEmbedding().to(DEVICE)
        fusion_spec_ft = MobileNetV2Embedding(freeze=False).to(DEVICE)
        fusion_clf_ft = FusionClassifier().to(DEVICE)
        fusion_ckpt = torch.load(fusion_finetuned_best_ckpt_path, map_location=DEVICE)
        # Load fine-tuned weights if they exist in the checkpoint
        if 'sinc' in fusion_ckpt: load_state_dict_flexible(fusion_sinc_ft, fusion_ckpt['sinc'])
        else: print("Warning: Fine-tuned SincNet state not found in fusion checkpoint, loading original best."); load_state_dict_flexible(fusion_sinc_ft, torch.load(sinc_best_ckpt_path, map_location=DEVICE)['model'])
        if 'spec' in fusion_ckpt: load_state_dict_flexible(fusion_spec_ft, fusion_ckpt['spec'], strict=False)
        else: print("Warning: Fine-tuned MobileNetV2 state not found in fusion checkpoint, loading original best."); load_state_dict_flexible(fusion_spec_ft, torch.load(mobilenet_best_ckpt_path, map_location=DEVICE)['model'], strict=False)
        load_state_dict_flexible(fusion_clf_ft, fusion_ckpt['clf'])
        models_to_evaluate['fusion_finetuned'] = (fusion_sinc_ft, fusion_spec_ft, fusion_clf_ft)
        print(f"Loaded Fine-tuned Fusion model components from {fusion_finetuned_best_ckpt_path}.")
    except Exception as e: print(f"ERROR loading Fine-tuned Fusion model components: {e}")
else: print(f"Fine-tuned Fusion checkpoint not found: {fusion_finetuned_best_ckpt_path}")

# --- Run Evaluation ---
all_results = {}
target_fnmrs = [0.01, 0.001] # FNMR targets (1%, 0.1%)

for condition in test_csv_paths.keys(): # clean, noisy, filtered
    print(f"\n--- Evaluating Condition: {condition.upper()} ---")
    all_results[condition] = {}

    raw_csv_path = test_csv_paths[condition]['raw']
    spec_csv_path = test_csv_paths[condition]['spec']
    if not raw_csv_path.exists(): print(f"  ERROR: Raw test CSV not found: {raw_csv_path}. Skipping {condition}."); continue
    if not spec_csv_path.exists(): print(f"  ERROR: Spectrogram test CSV not found: {spec_csv_path}. Skipping {condition}."); continue

    try:
        raw_ds = RawAudioDatasetPreprocessed(raw_csv_path)
        spec_ds = MelSpectrogramPairDataset(spec_csv_path)
        if len(raw_ds) != len(spec_ds): print(f"  WARNING: Length mismatch for {condition}! Raw: {len(raw_ds)}, Spec: {len(spec_ds)}.")
        if len(raw_ds) == 0: print(f"  WARNING: Test datasets for {condition} are empty."); continue
        raw_loader = DataLoader(raw_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)
        spec_loader = DataLoader(spec_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)
        print(f"  Loaded {len(raw_ds)} test pairs for {condition}.")
    except Exception as e: print(f"  ERROR loading dataset for {condition}: {e}. Skipping."); continue

    for model_name, components in models_to_evaluate.items():
        print(f"  Evaluating model: {model_name}...")
        y_true, y_score = None, None
        try:
            start_time = time.time()
            if model_name == 'sincnet_original':
                y_true, y_score = get_scores('sincnet', components, raw_loader, DEVICE)
            elif model_name == 'mobilenet_original':
                y_true, y_score = get_scores('mobilenet', components, spec_loader, DEVICE)
            elif model_name == 'fusion_finetuned':
                sinc, spec, clf = components
                sinc.eval(); spec.eval(); clf.eval()
                fusion_scores = []; fusion_labels = []
                with torch.no_grad():
                    raw_iter = iter(raw_loader); spec_iter = iter(spec_loader)
                    num_batches = min(len(raw_loader), len(spec_loader))
                    for _ in tqdm(range(num_batches), desc=f"Eval fine-tuned fusion ({condition})", leave=False):
                        w1, w2, y_raw = next(raw_iter); i1, i2, _ = next(spec_iter)
                        y = y_raw.float().to(DEVICE); fusion_labels.append(y.cpu())
                        autocast_args = {'device_type': DEVICE.type, 'enabled': (DEVICE.type == 'cuda')}
                        try:
                            with torch.amp.autocast(**autocast_args):
                                a1 = sinc(w1.to(DEVICE)); a2 = sinc(w2.to(DEVICE))
                                s1 = spec(i1.to(DEVICE)); s2 = spec(i2.to(DEVICE))
                                logits = clf(a1, a2, s1, s2)
                        except AttributeError:
                             with torch.cuda.amp.autocast(enabled=(DEVICE.type == 'cuda')): # Fallback
                                a1 = sinc(w1.to(DEVICE)); a2 = sinc(w2.to(DEVICE))
                                s1 = spec(i1.to(DEVICE)); s2 = spec(i2.to(DEVICE))
                                logits = clf(a1, a2, s1, s2)
                        fusion_scores.append(logits.cpu())
                y_true = torch.cat(fusion_labels).numpy(); y_score = torch.cat(fusion_scores).numpy()
            else: continue
            eval_time = time.time() - start_time

            if y_true is not None and y_score is not None and len(y_true) > 0:
                eer, eer_thresh = calculate_eer(y_true, y_score)
                auc_score = roc_auc_score(y_true, y_score)
                results = {'EER (%)': eer, 'AUC': auc_score, 'EER_Threshold': eer_thresh, 'Eval_Time (s)': eval_time, 'Num_Samples': len(y_true)}
                for target_fnmr in target_fnmrs:
                    fmr, thresh, actual_fnmr = calculate_fmr_at_fnmr(y_true, y_score, target_fnmr)
                    results[f'FMR_at_FNMR_{target_fnmr*100:.1f}% (%)'] = fmr
                    results[f'Threshold_at_FNMR_{target_fnmr*100:.1f}%'] = thresh
                    results[f'Actual_FNMR_at_Target_{target_fnmr*100:.1f}%'] = actual_fnmr
                all_results[condition][model_name] = results
                print(f"    {model_name}: EER={eer:.2f}%, AUC={auc_score:.4f}, Time={eval_time:.2f}s")
            else: print(f"    {model_name}: Evaluation failed (no scores/labels)."); all_results[condition][model_name] = {"error": "Score/label generation failed"}
        except Exception as e: print(f"  ERROR evaluating {model_name} on {condition}: {e}"); import traceback; traceback.print_exc(); all_results[condition][model_name] = {"error": str(e)}

# --- Save Results ---
print(f"\n--- Saving evaluation results to {RESULTS_FILE} ---")
RESULTS_FILE.parent.mkdir(parents=True, exist_ok=True)
try:
    def convert_numpy_floats(obj):
        if isinstance(obj, dict): return {k: convert_numpy_floats(v) for k, v in obj.items()}
        elif isinstance(obj, list): return [convert_numpy_floats(elem) for elem in obj]
        elif isinstance(obj, (np.float32, np.float64, np.float_)): return float(obj)
        elif isinstance(obj, np.ndarray): return obj.tolist()
        return obj
    serializable_results = convert_numpy_floats(all_results)
    with open(RESULTS_FILE, 'w') as f:
        json.dump(serializable_results, f, indent=4)
    print("Results saved successfully.")
except Exception as e: print(f"ERROR saving results: {e}")

# --- Display Results ---
print("\n--- Evaluation Summary ---")
print(json.dumps(serializable_results, indent=4))

"""## Train Fusion Model (From Scratch)

Train the final fusion model using the best SincNet checkpoint and the best MobileNetV2 checkpoint (from step 3), using the prepared local datasets.

#### fix corrupted spectrogram
"""

import librosa
import numpy as np
import torch
import torchaudio
import torchaudio.transforms as T
from PIL import Image
from pathlib import Path
import matplotlib.pyplot as plt # For saving without extra axes

# --- Parameters (Match your desired settings) ---
#  --n_mels 80 --n_fft 512 --hop_length 160 --img_size 224 --img_format png --duration 3.0
TARGET_SR = 16000
N_MELS = 80
N_FFT = 512
HOP_LENGTH = 160
IMG_SIZE = (224, 224) # Height, Width for PIL resize
DURATION_SECS = 3.0
TARGET_LEN_SAMPLES = int(TARGET_SR * DURATION_SECS)
IMG_FORMAT = 'png' # Should be 'png' for better quality

# --- File Paths ---
# The corrupted PNG file path (from the error message)
corrupted_png_path_str = "/content/data/spectrograms/noisy_train/id10017/7QOGR0zvTxY/00002.png"
corrupted_png_path = Path(corrupted_png_path_str)

# Infer the corresponding source WAV path (assuming structure matches)
# IMPORTANT: Verify this source path is correct and the WAV exists locally!
source_wav_path_str = "/content/drive/Shareddrives/VoxCeleb1/Dev_Augmented/wav/id10017/7QOGR0zvTxY/00002.wav"
source_wav_path = Path(source_wav_path_str)

print(f"Attempting to regenerate: {corrupted_png_path}")
print(f"Using source WAV: {source_wav_path}")

# --- Check if source WAV exists ---
if not source_wav_path.exists():
    print(f"ERROR: Source WAV file not found at {source_wav_path}. Cannot regenerate.")
    # Optional: Add code here to copy the specific WAV file if needed
    # !mkdir -p "{source_wav_path.parent}"
    # !cp "/path/on/drive/to/id10017/7QOGR0zvTxY/00002.wav" "{source_wav_path}"
else:
    try:
        # 1. Load and preprocess audio
        audio, sr = librosa.load(source_wav_path, sr=TARGET_SR, mono=True)

        # Pad or truncate
        if len(audio) > TARGET_LEN_SAMPLES:
            audio = audio[:TARGET_LEN_SAMPLES]
        elif len(audio) < TARGET_LEN_SAMPLES:
            audio = np.pad(audio, (0, TARGET_LEN_SAMPLES - len(audio)), mode='constant')

        audio_tensor = torch.from_numpy(audio).float()

        # 2. Create Mel Spectrogram
        mel_spectrogram_transform = T.MelSpectrogram(
            sample_rate=TARGET_SR,
            n_fft=N_FFT,
            hop_length=HOP_LENGTH,
            n_mels=N_MELS,
            power=2.0 # Power spectrogram
        )
        mel_spec = mel_spectrogram_transform(audio_tensor)

        # 3. Convert to dB scale (common practice)
        amplitude_to_db_transform = T.AmplitudeToDB(stype='power', top_db=80)
        mel_spec_db = amplitude_to_db_transform(mel_spec)

        # 4. Normalize (optional but common: scale to 0-1 or -1 to 1)
        # Example: Min-max scaling to 0-1
        min_val = torch.min(mel_spec_db)
        max_val = torch.max(mel_spec_db)
        if max_val > min_val:
             mel_spec_norm = (mel_spec_db - min_val) / (max_val - min_val)
        else:
             mel_spec_norm = torch.zeros_like(mel_spec_db) # Avoid division by zero

        # 5. Convert to PIL Image (repeat channel for RGB)
        # Permute dimensions if needed (e.g., if shape is [Mels, Time])
        # Convert to numpy array
        mel_spec_np = mel_spec_norm.numpy()

        # Use matplotlib to save as image without axes/whitespace
        # This often gives better control than direct PIL conversion for spectrograms
        fig = plt.figure(figsize=(IMG_SIZE[1]/100.0, IMG_SIZE[0]/100.0), dpi=100) # Control size via figsize and dpi
        ax = fig.add_axes([0, 0, 1, 1]) # Fill the entire figure
        ax.imshow(mel_spec_np, aspect='auto', origin='lower', cmap='viridis') # 'viridis' is common, adjust if needed
        ax.axis('off') # No axes

        # Ensure output directory exists
        corrupted_png_path.parent.mkdir(parents=True, exist_ok=True)

        # Save the figure
        plt.savefig(corrupted_png_path, format=IMG_FORMAT, bbox_inches='tight', pad_inches=0, dpi=100)
        plt.close(fig) # Close the figure to free memory

        # # Alternative: Direct PIL conversion (might need adjustments)
        # # Ensure shape is (H, W) before converting
        # if mel_spec_np.ndim == 3 and mel_spec_np.shape[0] == 1: # Remove channel dim if present
        #      mel_spec_np = mel_spec_np.squeeze(0)
        # # Scale to 0-255 for standard image formats
        # img_array = (mel_spec_norm * 255).byte().cpu().numpy()
        # # Create PIL image (assuming H, W format)
        # pil_img = Image.fromarray(img_array, mode='L') # Grayscale
        # # Resize
        # pil_img = pil_img.resize((IMG_SIZE[1], IMG_SIZE[0]), Image.Resampling.LANCZOS)
        # # Convert to RGB by duplicating channels
        # pil_img_rgb = pil_img.convert("RGB")
        # # Save
        # pil_img_rgb.save(corrupted_png_path, format=IMG_FORMAT.upper())

        print(f"Successfully regenerated and saved: {corrupted_png_path}")

    except Exception as e:
        print(f"ERROR regenerating file {corrupted_png_path}: {e}")
        import traceback
        traceback.print_exc()

os.chdir(WORKSPACE)
# Define input CSVs (pointing to local preprocessed raw and local spec data)
RAW_TRAIN_PREPROCESSED_CSV = f"{WORKSPACE}/data/pairs/pairs_raw_train_preprocessed_local.csv"
SPEC_TRAIN_CSV_LOCAL = f"{WORKSPACE}/data/pairs/pairs_spec_train_local.csv" # Copied/verified in step 2

# Define paths to best embedder checkpoints
SINC_BEST_CKPT = "outputs/checkpoints/sincnet_best.pt" # Assumes this exists
MOBILENET_BEST_CKPT = "outputs/checkpoints/mobilenetv2_best.pt" # From step 3

# Clean previous Fusion outputs
print("Cleaning previous Fusion outputs...")
# !rm -f outputs/checkpoints/fusion_*.pt
# !rm -f outputs/metrics/fusion_*.json

print("--- Starting Fusion Model Training From Scratch ---")
!python -m scripts.train_fusion \
  "{RAW_TRAIN_PREPROCESSED_CSV}" \
  "{SPEC_TRAIN_CSV_LOCAL}" \
  --sincnet_ckpt "{SINC_BEST_CKPT}" \
  --mobilenet_ckpt "{MOBILENET_BEST_CKPT}" \
  --output_dir outputs \
  --device cuda \
  --epochs 50 \
  --batch_size 256 \
  --num_workers 8 \
  --lr 1e-4 \
  --patience 5 \
  --seed 42 \
  --freeze_embedders # Keep SincNet/MobileNet frozen (default)
  # DO NOT USE --resume

"""#Test +Evaluations

## Prepare *Test* Data Locally (Raw NPY)

* Copies original raw test WAVs (clean, noisy, filtered) from Drive to local.
* Pre-processes local WAVs into local `.npy` format (also saves NPY to Drive).
* Generates `*_preprocessed_local.csv` and `*_preprocessed_drive.csv` files on Drive.
"""

# Commented out IPython magic to ensure Python compatibility.
print("--- Preparing Raw Test Data Locally (Copying WAVs, Preprocessing to NPY, Generating NPY CSVs) ---")
!mkdir data
!mkdir data/raw_audio_preprocessed
!cp -rv /content/drive/Shareddrives/VoiceAuth/data/raw_audio_preprocessed/noisy_test/ /content/data/raw_audio_preprocessed/
!cp -rv /content/drive/Shareddrives/VoiceAuth/data/raw_audio_preprocessed/filtered_test/ /content/data/raw_audio_preprocessed/
!cp -rv /content/drive/Shareddrives/VoiceAuth/data/raw_audio_preprocessed/clean_test/ /content/data/raw_audio_preprocessed/
# %cd /content/drive/Shareddrives/VoiceAuth
# !python -m scripts.data_manager_v2 \
#   --drive_workspace_dir="{WORKSPACE}" \
#   --copy_raw_test --preprocess_raw_test --gen_csv_local --gen_csv_drive \
#   --force_preprocess # Ensure test NPYs are generated
#   # --force_copy # Optional: Overwrite existing local WAV files

"""## Regenerate *Test* Spectrograms Locally (Higher Quality)

* Uses local raw WAVs copied/verified in the previous step.
* Generates PNG images locally.
* Saves the CSVs (with local paths) to Drive.
"""

print("--- Regenerating TEST Spectrograms Locally (Higher Quality) ---")

# Define local output directories for spectrogram images
LOCAL_SPEC_DIR_CLEAN = "/content/data/spectrograms/clean_test/"
LOCAL_SPEC_DIR_NOISY = "/content/data/spectrograms/noisy_test/"
LOCAL_SPEC_DIR_FILTERED = "/content/data/spectrograms/filtered_test/"

# Define input raw pair CSVs (original ones on Drive)
RAW_CSV_CLEAN = f"{WORKSPACE}/data/pairs/pairs_raw_clean_test.csv"
RAW_CSV_NOISY = f"{WORKSPACE}/data/pairs/pairs_raw_noisy_test.csv"
RAW_CSV_FILTERED = f"{WORKSPACE}/data/pairs/pairs_raw_filtered_test.csv"

# Define output spectrogram pair CSVs (containing LOCAL paths, saved to Drive)
SPEC_CSV_LOCAL_CLEAN = f"{WORKSPACE}/data/pairs/pairs_spec_clean_test_local.csv"
SPEC_CSV_LOCAL_NOISY = f"{WORKSPACE}/data/pairs/pairs_spec_noisy_test_local.csv"
SPEC_CSV_LOCAL_FILTERED = f"{WORKSPACE}/data/pairs/pairs_spec_filtered_test_local.csv"

# Ensure local output directories exist and are clean
!mkdir -p {LOCAL_SPEC_DIR_CLEAN}; !rm -rf {LOCAL_SPEC_DIR_CLEAN}/*
!mkdir -p {LOCAL_SPEC_DIR_NOISY}; !rm -rf {LOCAL_SPEC_DIR_NOISY}/*
!mkdir -p {LOCAL_SPEC_DIR_FILTERED}; !rm -rf {LOCAL_SPEC_DIR_FILTERED}/*

print("Generating Clean Test Spectrograms...")
!python -m scripts.make_spectrogram_pairs \
  "{RAW_CSV_CLEAN}" \
  "{LOCAL_SPEC_DIR_CLEAN}" \
  "{SPEC_CSV_LOCAL_CLEAN}" \
  --n_mels 80 --n_fft 512 --hop_length 160 --img_size 224 --img_format png --duration 3.0

print("Generating Noisy Test Spectrograms...")
!python -m scripts.make_spectrogram_pairs \
  "{RAW_CSV_NOISY}" \
  "{LOCAL_SPEC_DIR_NOISY}" \
  "{SPEC_CSV_LOCAL_NOISY}" \
  --n_mels 80 --n_fft 512 --hop_length 160 --img_size 224 --img_format png --duration 3.0

print("Generating Filtered Test Spectrograms...")
!python -m scripts.make_spectrogram_pairs \
  "{RAW_CSV_FILTERED}" \
  "{LOCAL_SPEC_DIR_FILTERED}" \
  "{SPEC_CSV_LOCAL_FILTERED}" \
  --n_mels 80 --n_fft 512 --hop_length 160 --img_size 224 --img_format png --duration 3.0

from tqdm.notebook import tqdm
import os
import shutil

# copy test spectrograms to drive
SRC_DIRS = [
    LOCAL_SPEC_DIR_CLEAN,
    LOCAL_SPEC_DIR_NOISY,
    LOCAL_SPEC_DIR_FILTERED
]

DEST_ROOT = "/content/drive/Shareddrives/VoiceAuth/data/spectrograms"

for src_dir in tqdm(SRC_DIRS, desc="Directories", unit="dir"):
    if not os.path.isdir(src_dir):
        print(f"Skipping missing: {src_dir}")
        continue

    name = os.path.basename(os.path.normpath(src_dir))
    dest = os.path.join(DEST_ROOT, name)
    if os.path.exists(dest):
        shutil.rmtree(dest)

    # gather all files under this src_dir
    files = []
    for root, _, fnames in os.walk(src_dir):
        for f in fnames:
            files.append(os.path.join(root, f))

    # inner progress bar for files
    for src in tqdm(files, desc=f"Copying {name}", unit="file", leave=False):
        rel = os.path.relpath(src, src_dir)
        dst = os.path.join(dest, rel)
        os.makedirs(os.path.dirname(dst), exist_ok=True)
        shutil.copy2(src, dst)

print("✅ All done! Stored all data under /content/data/")

"""## Evaluate Models (Extensive Metrics)

Evaluate the best SincNet, MobileNetV2, and Fusion models on all three test conditions using the locally prepared data (regenerated spectrograms).
"""

!python -m scripts.evaluate_models \
    --workspace /content/drive/Shareddrives/VoiceAuth/ \
    --output-dir /content/drive/Shareddrives/VoiceAuth/outputs \
    --batch-size 256 \
    --num-workers 8